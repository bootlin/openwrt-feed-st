From 75d45914347d61b41fcd01f61934ea1d69a01653 Mon Sep 17 00:00:00 2001
From: Amelie Delaunay <amelie.delaunay@foss.st.com>
Date: Wed, 21 Feb 2024 10:13:09 +0100
Subject: [PATCH] dmaengine: stm32-dma3: add DMA3 v1.6 support used on
 stm32mp21

DMA3 v1.6 differs from previous versions with:
- CxSR.FIFOL in bytes instead of in unit of destination data width
- CxCR.DRAINFIFO used to drain last FIFO bytes to the destination when
terminating an ongoing transfer.

Change-Id: Ic0403c7c083eea2814980d127c2ef991758b8def
Signed-off-by: Amelie Delaunay <amelie.delaunay@foss.st.com>
Reviewed-on: https://gerrit.st.com/c/mpu/oe/st/linux-stm32/+/373118
ACI: CIBUILD <MDG-smet-aci-builds@list.st.com>
ACI: CITOOLS <MDG-smet-aci-reviews@list.st.com>
---
 drivers/dma/stm32/stm32-dma3.c | 90 ++++++++++++++++++++++++++++------
 1 file changed, 76 insertions(+), 14 deletions(-)

diff --git a/drivers/dma/stm32/stm32-dma3.c b/drivers/dma/stm32/stm32-dma3.c
index a23d0c80092d..8ced23432fce 100644
--- a/drivers/dma/stm32/stm32-dma3.c
+++ b/drivers/dma/stm32/stm32-dma3.c
@@ -104,6 +104,7 @@ enum ccidcfgr_cid {
 #define CCR_EN				BIT(0)
 #define CCR_RESET			BIT(1)
 #define CCR_SUSP			BIT(2)
+#define CCR_DRAINFIFO			BIT(3)
 #define CCR_TCIE			BIT(8)
 #define CCR_HTIE			BIT(9)
 #define CCR_DTEIE			BIT(10)
@@ -211,6 +212,8 @@ enum stm32_dma3_port_data_width {
 /* VERR DMA version register */
 #define VERR_MINREV			GENMASK(3, 0)
 #define VERR_MAJREV			GENMASK(7, 4)
+#define STM32_DMA3_VERSION(major, minor)(FIELD_PREP(VERR_MAJREV, (major)) | \
+					 FIELD_PREP(VERR_MINREV, (minor)))
 
 /* Device tree */
 /* struct stm32_dma3_dt_conf */
@@ -301,6 +304,11 @@ struct stm32_dma3_chan {
 	u32 dma_status;
 };
 
+struct stm32_dma3_ops {
+	bool fifol_in_bytes;
+	bool drain_fifo;
+};
+
 struct stm32_dma3_ddata {
 	struct dma_device dma_dev;
 	void __iomem *base;
@@ -314,6 +322,7 @@ struct stm32_dma3_ddata {
 	u32 lap;
 	struct gen_pool *gen_pool;
 	struct dma_pool *dma_pool;
+	struct stm32_dma3_ops ops;
 };
 
 static inline struct stm32_dma3_ddata *to_stm32_dma3_ddata(struct stm32_dma3_chan *chan)
@@ -1053,6 +1062,31 @@ static int stm32_dma3_chan_suspend(struct stm32_dma3_chan *chan, bool susp)
 	return ret;
 }
 
+static int stm32_dma3_chan_terminate(struct stm32_dma3_chan *chan)
+{
+	struct stm32_dma3_ddata *ddata = to_stm32_dma3_ddata(chan);
+	u32 csr, ccr = readl_relaxed(ddata->base + STM32_DMA3_CCR(chan->id)) & ~CCR_EN;
+	int ret;
+
+	/* Channel is already suspended and fifo can't be drained */
+	if (ccr & CCR_SUSP && !ddata->ops.drain_fifo)
+		return 0;
+
+	ccr |= CCR_SUSP;
+	if (ddata->ops.drain_fifo)
+		ccr |= CCR_DRAINFIFO;
+
+	writel_relaxed(ccr, ddata->base + STM32_DMA3_CCR(chan->id));
+
+	ret = readl_relaxed_poll_timeout_atomic(ddata->base + STM32_DMA3_CSR(chan->id), csr,
+						csr & (CSR_SUSPF | CSR_TCF), 1, 10);
+	if (ret)
+		dev_warn(chan2dev(chan), "%s: timeout, data might be lost (ccr=%08x csr=%08x)\n",
+			 __func__, ccr, csr);
+
+	return ret;
+}
+
 static void stm32_dma3_chan_reset(struct stm32_dma3_chan *chan)
 {
 	struct stm32_dma3_ddata *ddata = to_stm32_dma3_ddata(chan);
@@ -1091,7 +1125,7 @@ static void stm32_dma3_chan_set_residue(struct stm32_dma3_chan *chan,
 	struct stm32_dma3_ddata *ddata = to_stm32_dma3_ddata(chan);
 	struct device *dev = chan2dev(chan);
 	struct stm32_dma3_hwdesc *hwdesc;
-	u32 residue, curr_lli, csr, cdar, cbr1, cllr, bndt, fifol;
+	u32 residue, curr_lli, csr, cdar = 0, cbr1, cllr, bndt, fifol;
 	bool pack_unpack;
 	int ret;
 
@@ -1124,7 +1158,8 @@ static void stm32_dma3_chan_set_residue(struct stm32_dma3_chan *chan,
 	/* Read registers to have a snapshot */
 	cllr = readl_relaxed(ddata->base + STM32_DMA3_CLLR(chan->id));
 	cbr1 = readl_relaxed(ddata->base + STM32_DMA3_CBR1(chan->id));
-	cdar = readl_relaxed(ddata->base + STM32_DMA3_CDAR(chan->id));
+	if (!ddata->ops.fifol_in_bytes)
+		cdar = readl_relaxed(ddata->base + STM32_DMA3_CDAR(chan->id));
 
 	/* Resume current transfer */
 	if (csr & CSR_SUSPF) {
@@ -1144,12 +1179,17 @@ static void stm32_dma3_chan_set_residue(struct stm32_dma3_chan *chan,
 	}
 	curr_lli = ret;
 
-	/* Read current FIFO level - in units of programmed destination data width */
-	hwdesc = swdesc->lli[curr_lli].hwdesc;
-	fifol = FIELD_GET(CSR_FIFOL, csr) * (1 << FIELD_GET(CTR1_DDW_LOG2, hwdesc->ctr1));
-	/* If the FIFO contains as many bytes as its size, it can't contain more */
-	if (fifol == (1 << (chan->fifo_size + 1)))
+	/* Read current FIFO level */
+	if (ddata->ops.fifol_in_bytes) {
+		fifol = FIELD_GET(CSR_FIFOL, csr);
 		goto skip_fifol_update;
+	} else { /* FIFO level in units of programmed destination data width */
+		hwdesc = swdesc->lli[curr_lli].hwdesc;
+		fifol = FIELD_GET(CSR_FIFOL, csr) * (1 << FIELD_GET(CTR1_DDW_LOG2, hwdesc->ctr1));
+		/* If the FIFO contains as many bytes as its size, it can't contain more */
+		if (fifol == (1 << (chan->fifo_size + 1)))
+			goto skip_fifol_update;
+	}
 
 	/*
 	 * In case of PACKING (Destination burst length > Source burst length) or UNPACKING
@@ -1201,16 +1241,16 @@ static int stm32_dma3_chan_stop(struct stm32_dma3_chan *chan)
 	ccr = readl_relaxed(ddata->base + STM32_DMA3_CCR(chan->id));
 	writel_relaxed(ccr & ~(CCR_ALLIE | CCR_EN), ddata->base + STM32_DMA3_CCR(chan->id));
 
-	if (!(ccr & CCR_SUSP) && (ccr & CCR_EN)) {
-		/* Suspend the channel */
-		ret = stm32_dma3_chan_suspend(chan, true);
-		if (ret)
-			dev_warn(chan2dev(chan), "%s: timeout, data might be lost\n", __func__);
-	}
+	if (!(ccr & CCR_EN))
+		goto skip_terminate;
+
+	/* Terminate the channel */
+	ret = stm32_dma3_chan_terminate(chan);
 
+skip_terminate:
 	/*
 	 * Reset the channel: this causes the reset of the FIFO and the reset of the channel
-	 * internal state, the reset of CCR_EN and CCR_SUSP bits.
+	 * internal state, the reset of CCR_SUSP (and CCR_DRAINFIFO) and CCR_EN bits.
 	 */
 	stm32_dma3_chan_reset(chan);
 
@@ -1337,6 +1377,15 @@ static int stm32_dma3_alloc_chan_resources(struct dma_chan *c)
 	struct stm32_dma3_ddata *ddata = to_stm32_dma3_ddata(chan);
 	int ret;
 
+	/*
+	 * At this point, chan->dma_config is either allocated with __GFP_ZERO or memset 0,
+	 * so chan->dma_config.direction == 0 (== DMA_MEM_TO_MEM).
+	 * This driver relies on chan->dma_config.direction for _tx_status and _terminate_all ops.
+	 * Initialize it with DMA_TRANS_NONE so that the driver knows that the channel direction
+	 * has not yet been configured.
+	 */
+	chan->dma_config.direction = DMA_TRANS_NONE;
+
 	ret = pm_runtime_resume_and_get(ddata->dma_dev.dev);
 	if (ret < 0)
 		return ret;
@@ -1386,6 +1435,7 @@ static void stm32_dma3_free_chan_resources(struct dma_chan *c)
 	/* Reset configuration */
 	memset(&chan->dt_config, 0, sizeof(chan->dt_config));
 	memset(&chan->dma_config, 0, sizeof(chan->dma_config));
+	chan->dma_config.direction = DMA_TRANS_NONE;
 	chan->config_set = 0;
 }
 
@@ -1702,6 +1752,14 @@ static int stm32_dma3_config(struct dma_chan *c, struct dma_slave_config *config
 	struct stm32_dma3_chan *chan = to_stm32_dma3_chan(c);
 
 	memcpy(&chan->dma_config, config, sizeof(*config));
+	/*
+	 * This driver uses the direction argument to the device_prep_slave_sg/_dma_cyclic functions
+	 * to set chan->dma_config.direction. So config->direction potentially set before is not
+	 * used. This driver relies on chan->dma_config.direction for _tx_status and _terminate_all
+	 * ops. Overwrite it here so that the driver knows that the channel direction has not yet
+	 * been configured.
+	 */
+	chan->dma_config.direction = DMA_TRANS_NONE;
 	chan->config_set |= STM32_DMA3_CFG_SET_DMA;
 
 	return 0;
@@ -2160,6 +2218,10 @@ static int stm32_dma3_probe(struct platform_device *pdev)
 	}
 
 	verr = readl_relaxed(ddata->base + STM32_DMA3_VERR);
+	if (verr >= STM32_DMA3_VERSION(1, 6)) {
+		ddata->ops.fifol_in_bytes = true;
+		ddata->ops.drain_fifo = true;
+	}
 
 	pm_runtime_set_active(&pdev->dev);
 	pm_runtime_enable(&pdev->dev);
-- 
2.39.5

