From 74e2fea871abc042c496fe3114253cdb16f0a5b5 Mon Sep 17 00:00:00 2001
From: Amelie Delaunay <amelie.delaunay@foss.st.com>
Date: Fri, 12 Apr 2024 16:21:56 +0200
Subject: [PATCH] dmaengine: stm32-dma3: add support for AXI port address
 remapping

When AXI port address remapping is enabled, the 4GB address space
accessible by the DMA3 AXI port starts at address 0x80000000. It means that
peripherals and internal RAMs, in 2GB address space starting at 0x00000000
are not accessible with AXI port, so AHB port must be used.

When AXI port address remapping is disabled, the 4GB address space
accessible by the DMA3 AXI port starts at address 0x00000000. It means that
DDR beyond 2GB is not accessible (whatever the port AXI or AHB).

LL allocated port must also take into account this constraint: AXI port is
used by default, but if Linked-List are allocated in internal RAM, AHB port
must be used in case AXI port address remapping is enabled.

Signed-off-by: Amelie Delaunay <amelie.delaunay@foss.st.com>
Change-Id: Ib5fc457b5a3cfc3e741c65b8d2ebd351ce7238a7
Reviewed-on: https://gerrit.st.com/c/mpu/oe/st/linux-stm32/+/373117
ACI: CIBUILD <MDG-smet-aci-builds@list.st.com>
---
 drivers/dma/stm32/stm32-dma3.c | 177 +++++++++++++++++++++++++++++----
 1 file changed, 159 insertions(+), 18 deletions(-)

diff --git a/drivers/dma/stm32/stm32-dma3.c b/drivers/dma/stm32/stm32-dma3.c
index d2f0bc1fbe40..a23d0c80092d 100644
--- a/drivers/dma/stm32/stm32-dma3.c
+++ b/drivers/dma/stm32/stm32-dma3.c
@@ -15,11 +15,13 @@
 #include <linux/init.h>
 #include <linux/iopoll.h>
 #include <linux/list.h>
+#include <linux/mfd/syscon.h>
 #include <linux/module.h>
 #include <linux/of_dma.h>
 #include <linux/of_reserved_mem.h>
 #include <linux/platform_device.h>
 #include <linux/pm_runtime.h>
+#include <linux/regmap.h>
 #include <linux/reset.h>
 #include <linux/slab.h>
 
@@ -308,6 +310,7 @@ struct stm32_dma3_ddata {
 	u32 dma_requests;
 	enum stm32_dma3_port_data_width ports_max_dw[2];
 	u32 axi_max_burst_len;
+	phys_addr_t axi_addr_offset;
 	u32 lap;
 	struct gen_pool *gen_pool;
 	struct dma_pool *dma_pool;
@@ -333,11 +336,28 @@ static struct device *chan2dev(struct stm32_dma3_chan *chan)
 	return &chan->vchan.chan.dev->device;
 }
 
+static dma_addr_t stm32_dma3_translate_addr(struct stm32_dma3_ddata *ddata, u32 port,
+					    struct device *client, dma_addr_t dma_addr)
+{
+	/*
+	 * If port used is AHB or address is already below the 2G addressable space,
+	 * don't force translation: there is no HW translation on AHB port and either DMA client
+	 * buffer allocation has taken dma-ranges into account or there is no HW translation, so
+	 * no dma-ranges, so addresses are not and must not be translated by this driver.
+	 */
+	if (port_is_ahb(ddata->ports_max_dw[port]) || (client && client->dma_range_map) ||
+	    dma_addr < ddata->axi_addr_offset)
+		return dma_addr;
+
+	return dma_addr - ddata->axi_addr_offset;
+}
+
 static void stm32_dma3_chan_dump_reg(struct stm32_dma3_chan *chan)
 {
 	struct stm32_dma3_ddata *ddata = to_stm32_dma3_ddata(chan);
 	struct device *dev = chan2dev(chan);
-	u32 id = chan->id, offset;
+	u32 id = chan->id, offset, value;
+	bool axi_port_used = false, axi_used;
 
 	offset = STM32_DMA3_SECCFGR;
 	dev_dbg(dev, "SECCFGR(0x%03x): %08x\n", offset, readl_relaxed(ddata->base + offset));
@@ -347,43 +367,67 @@ static void stm32_dma3_chan_dump_reg(struct stm32_dma3_chan *chan)
 	dev_dbg(dev, "C%dCIDCFGR(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
 	offset = STM32_DMA3_CSEMCR(id);
 	dev_dbg(dev, "C%dSEMCR(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
+	value = readl_relaxed(ddata->base + STM32_DMA3_CCR(id));
+	axi_used = port_is_axi(ddata->ports_max_dw[FIELD_GET(CCR_LAP, value)]);
+	offset = STM32_DMA3_CLBAR(id);
+	dev_dbg(dev, "C%dLBAR(0x%03x): %08x%s\n", id, offset, readl_relaxed(ddata->base + offset),
+		axi_used && ddata->axi_addr_offset ? " (*)" : "");
+	axi_port_used |= axi_used;
 	offset = STM32_DMA3_CSR(id);
 	dev_dbg(dev, "C%dSR(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
-	offset = STM32_DMA3_CCR(id);
-	dev_dbg(dev, "C%dCR(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
+	dev_dbg(dev, "C%dCR(0x%03x): %08x\n", id, offset, value); /* value = CR read earlier */
 	offset = STM32_DMA3_CTR1(id);
-	dev_dbg(dev, "C%dTR1(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
+	value = readl_relaxed(ddata->base + offset);
+	dev_dbg(dev, "C%dTR1(0x%03x): %08x\n", id, offset, value);
 	offset = STM32_DMA3_CTR2(id);
 	dev_dbg(dev, "C%dTR2(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
 	offset = STM32_DMA3_CBR1(id);
 	dev_dbg(dev, "C%dBR1(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
 	offset = STM32_DMA3_CSAR(id);
-	dev_dbg(dev, "C%dSAR(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
+	axi_used = port_is_axi(ddata->ports_max_dw[FIELD_GET(CTR1_SAP, value)]);
+	dev_dbg(dev, "C%dSAR(0x%03x): %08x%s\n", id, offset, readl_relaxed(ddata->base + offset),
+		axi_used && ddata->axi_addr_offset ? " (*)" : "");
+	axi_port_used |= axi_used;
 	offset = STM32_DMA3_CDAR(id);
-	dev_dbg(dev, "C%dDAR(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
+	axi_used = port_is_axi(ddata->ports_max_dw[FIELD_GET(CTR1_DAP, value)]);
+	dev_dbg(dev, "C%dDAR(0x%03x): %08x%s\n", id, offset, readl_relaxed(ddata->base + offset),
+		axi_used && ddata->axi_addr_offset ? " (*)" : "");
+	axi_port_used |= axi_used;
 	offset = STM32_DMA3_CLLR(id);
 	dev_dbg(dev, "C%dLLR(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
-	offset = STM32_DMA3_CLBAR(id);
-	dev_dbg(dev, "C%dLBAR(0x%03x): %08x\n", id, offset, readl_relaxed(ddata->base + offset));
+	if (axi_port_used && ddata->axi_addr_offset)
+		dev_dbg(dev, "(*) Address remapping enabled on AXI port, offset=%pap\n",
+			&ddata->axi_addr_offset);
 }
 
 static void stm32_dma3_chan_dump_hwdesc(struct stm32_dma3_chan *chan,
 					struct stm32_dma3_swdesc *swdesc)
 {
+	struct stm32_dma3_ddata *ddata = to_stm32_dma3_ddata(chan);
 	struct stm32_dma3_hwdesc *hwdesc;
+	bool axi_port_used = false;
 	int i;
 
 	for (i = 0; i < swdesc->lli_size; i++) {
+		bool axi_used = false;
+
 		hwdesc = swdesc->lli[i].hwdesc;
 		if (i)
 			dev_dbg(chan2dev(chan), "V\n");
-		dev_dbg(chan2dev(chan), "[%d]@%pad\n", i, &swdesc->lli[i].hwdesc_addr);
+		axi_used = port_is_axi(ddata->ports_max_dw[FIELD_GET(CCR_LAP, swdesc->ccr)]);
+		dev_dbg(chan2dev(chan), "[%d]@%pad%s\n", i, &swdesc->lli[i].hwdesc_addr,
+			axi_used && ddata->axi_addr_offset ? "(*)" : "");
 		dev_dbg(chan2dev(chan), "| C%dTR1: %08x\n", chan->id, hwdesc->ctr1);
 		dev_dbg(chan2dev(chan), "| C%dTR2: %08x\n", chan->id, hwdesc->ctr2);
 		dev_dbg(chan2dev(chan), "| C%dBR1: %08x\n", chan->id, hwdesc->cbr1);
-		dev_dbg(chan2dev(chan), "| C%dSAR: %08x\n", chan->id, hwdesc->csar);
-		dev_dbg(chan2dev(chan), "| C%dDAR: %08x\n", chan->id, hwdesc->cdar);
+		axi_used = port_is_axi(ddata->ports_max_dw[FIELD_GET(CTR1_SAP, hwdesc->ctr1)]);
+		dev_dbg(chan2dev(chan), "| C%dSAR: %08x%s\n", chan->id, hwdesc->csar,
+			axi_used && ddata->axi_addr_offset ? "(*)" : "");
+		axi_used = port_is_axi(ddata->ports_max_dw[FIELD_GET(CTR1_DAP, hwdesc->ctr1)]);
+		dev_dbg(chan2dev(chan), "| C%dDAR: %08x%s\n", chan->id, hwdesc->cdar,
+			axi_used && ddata->axi_addr_offset ? "(*)" : "");
 		dev_dbg(chan2dev(chan), "| C%dLLR: %08x\n", chan->id, hwdesc->cllr);
+		axi_port_used |= axi_used;
 	}
 
 	if (swdesc->cyclic) {
@@ -392,6 +436,10 @@ static void stm32_dma3_chan_dump_hwdesc(struct stm32_dma3_chan *chan,
 	} else {
 		dev_dbg(chan2dev(chan), "X\n");
 	}
+
+	if (axi_port_used && ddata->axi_addr_offset)
+		dev_dbg(chan2dev(chan), "Address remapping enabled on AXI port, offset=%pap\n",
+			&ddata->axi_addr_offset);
 }
 
 static int stm32_dma3_lli_pool_create(struct platform_device *pdev, struct stm32_dma3_ddata *ddata)
@@ -533,6 +581,7 @@ static struct stm32_dma3_swdesc *stm32_dma3_chan_desc_alloc(struct stm32_dma3_ch
 {
 	struct stm32_dma3_ddata *ddata = to_stm32_dma3_ddata(chan);
 	struct stm32_dma3_swdesc *swdesc;
+	dma_addr_t base_addr;
 	int ret;
 
 	/*
@@ -558,13 +607,37 @@ static struct stm32_dma3_swdesc *stm32_dma3_chan_desc_alloc(struct stm32_dma3_ch
 	}
 	swdesc->lli_size = count;
 
-	/* Set LL base address */
-	writel_relaxed(swdesc->lli[0].hwdesc_addr & CLBAR_LBA,
-		       ddata->base + STM32_DMA3_CLBAR(chan->id));
+	/*
+	 * Force using the second port (hopefully AHB) if addresses are remapped on AXI,
+	 * and LLI are in internal RAM.
+	 */
+	if (ddata->axi_addr_offset && ddata->ports_max_dw[1] != DW_INVALID &&
+	    ddata->gen_pool && gen_pool_has_addr(ddata->gen_pool, swdesc->lli[0].hwdesc_addr,
+						 sizeof(struct stm32_dma3_hwdesc))) {
+		if (port_is_ahb(ddata->ports_max_dw[1])) {
+			dev_notice(chan2dev(chan),
+				   "Address remapping enabled on AXI port, force LL port on AHB\n");
+			ddata->lap = 1;
+		} else { /* We should not enter this condition */
+			dev_err(chan2dev(chan),
+				"Address remapping enabled on AXI port, %pad unreachable for LL\n",
+				&swdesc->lli[0].hwdesc_addr);
+			kfree(swdesc);
+			return NULL;
+		}
+	}
 
 	/* Set LL allocated port */
 	swdesc->ccr = FIELD_PREP(CCR_LAP, ddata->lap);
 
+	/* Set LL base address */
+	base_addr = stm32_dma3_translate_addr(ddata, ddata->lap, chan2dev(chan),
+					      swdesc->lli[0].hwdesc_addr);
+	writel_relaxed(base_addr & CLBAR_LBA, ddata->base + STM32_DMA3_CLBAR(chan->id));
+	if (ddata->axi_addr_offset)
+		dev_dbg(chan2dev(chan), "Configured LL base=%pap, real LL base=%pap\n",
+			&base_addr, &swdesc->lli[0].hwdesc_addr);
+
 	return swdesc;
 }
 
@@ -624,6 +697,8 @@ static void stm32_dma3_chan_prep_hwdesc(struct stm32_dma3_chan *chan,
 					u32 curr, dma_addr_t src, dma_addr_t dst, u32 len,
 					u32 ctr1, u32 ctr2, bool is_last, bool is_cyclic)
 {
+	struct stm32_dma3_ddata *ddata = to_stm32_dma3_ddata(chan);
+	struct device *client = chan->vchan.chan.slave;
 	struct stm32_dma3_hwdesc *hwdesc;
 	dma_addr_t next_lli;
 	u32 next = curr + 1;
@@ -632,16 +707,18 @@ static void stm32_dma3_chan_prep_hwdesc(struct stm32_dma3_chan *chan,
 	hwdesc->ctr1 = ctr1;
 	hwdesc->ctr2 = ctr2;
 	hwdesc->cbr1 = FIELD_PREP(CBR1_BNDT, len);
-	hwdesc->csar = src;
-	hwdesc->cdar = dst;
+	hwdesc->csar = stm32_dma3_translate_addr(ddata, FIELD_GET(CTR1_SAP, ctr1), client, src);
+	hwdesc->cdar = stm32_dma3_translate_addr(ddata, FIELD_GET(CTR1_DAP, ctr1), client, dst);
 
 	if (is_last) {
 		if (is_cyclic)
-			next_lli = swdesc->lli[0].hwdesc_addr;
+			next_lli = stm32_dma3_translate_addr(ddata, ddata->lap, chan2dev(chan),
+							     swdesc->lli[0].hwdesc_addr);
 		else
 			next_lli = 0;
 	} else {
-		next_lli = swdesc->lli[next].hwdesc_addr;
+		next_lli = stm32_dma3_translate_addr(ddata, ddata->lap, chan2dev(chan),
+						     swdesc->lli[next].hwdesc_addr);
 	}
 
 	hwdesc->cllr = 0;
@@ -731,6 +808,24 @@ static int stm32_dma3_chan_prep_hw(struct stm32_dma3_chan *chan, enum dma_transf
 		return -EINVAL;
 	}
 
+	/*
+	 * with dma_range and HW translation, alert the client if using AHB port to access memory,
+	 * because client buffer will be translated during allocation, and DMA driver won't
+	 * add offset to fix the address: DMA will access the memory at the address given by the
+	 * client.
+	 */
+	if (WARN_ON(ddata->axi_addr_offset && chan->vchan.chan.slave->dma_range_map &&
+		    ((dir == DMA_DEV_TO_MEM && port_is_ahb(dap_max_dw)) ||
+		     (dir == DMA_MEM_TO_DEV && port_is_ahb(sap_max_dw)) ||
+		     (dir == DMA_MEM_TO_MEM && (port_is_ahb(sap_max_dw) ||
+						port_is_ahb(dap_max_dw)))))) {
+		dev_warn(chan2dev(chan), "%s: AHB port to access MEM at %pad, no DMA translation\n",
+			 dev_name(chan->vchan.chan.slave), dir == DMA_DEV_TO_MEM ? &dst_addr :
+							   dir == DMA_MEM_TO_DEV ? &src_addr :
+							   port_is_ahb(sap_max_dw) ? &src_addr :
+							   &dst_addr);
+	}
+
 	if (FIELD_GET(STM32_DMA3_DT_SINC, tr_conf))
 		_ctr1 |= CTR1_SINC;
 	if (sap)
@@ -1320,6 +1415,7 @@ static void stm32_dma3_init_chan_config_for_memcpy(struct stm32_dma3_chan *chan,
 						   dma_addr_t dst, dma_addr_t src)
 {
 	struct stm32_dma3_ddata *ddata = to_stm32_dma3_ddata(chan);
+	struct device *client = chan->vchan.chan.slave;
 	u32 dw = get_chan_max_dw(ddata->ports_max_dw[0], chan->max_burst); /* port 0 by default */
 	u32 burst = chan->max_burst / dw;
 
@@ -1328,6 +1424,15 @@ static void stm32_dma3_init_chan_config_for_memcpy(struct stm32_dma3_chan *chan,
 		chan->dt_config.ch_conf = FIELD_PREP(STM32_DMA3_DT_PRIO, CCR_PRIO_VERY_HIGH);
 		chan->dt_config.ch_conf |= FIELD_PREP(STM32_DMA3_DT_FIFO, chan->fifo_size);
 		chan->dt_config.tr_conf = STM32_DMA3_DT_SINC | STM32_DMA3_DT_DINC;
+		if (ddata->axi_addr_offset && ddata->ports_max_dw[1] != DW_INVALID) {
+			if (!client->dma_range_map) {
+				/* Use second port if no translation applies to the address */
+				if (stm32_dma3_translate_addr(ddata, 0, client, src) == src)
+					chan->dt_config.tr_conf |= STM32_DMA3_DT_SAP;
+				if (stm32_dma3_translate_addr(ddata, 0, client, dst) == dst)
+					chan->dt_config.tr_conf |= STM32_DMA3_DT_DAP;
+			}
+		}
 		chan->dt_config.tr_conf |= FIELD_PREP(STM32_DMA3_DT_TCEM, CTR2_TCEM_CHANNEL);
 	}
 
@@ -1779,6 +1884,35 @@ static struct dma_chan *stm32_dma3_of_xlate(struct of_phandle_args *dma_spec, st
 	return c;
 }
 
+static int stm32_dma3_get_axi_port_config(struct platform_device *pdev,
+					  struct stm32_dma3_ddata *ddata)
+{
+	char *name = "st,syscfg-arcr";
+	struct regmap *regmap;
+	int offset, mask, remap, ret;
+
+	ddata->axi_addr_offset = 0;
+	/* st,syscfg is optional */
+	regmap = syscon_regmap_lookup_by_phandle_optional(pdev->dev.of_node, name);
+	if (IS_ERR_OR_NULL(regmap))
+		return PTR_ERR_OR_ZERO(regmap);
+
+	ret = of_property_read_u32_index(pdev->dev.of_node, name, 1, &offset);
+	if (!ret)
+		ret = of_property_read_u32_index(pdev->dev.of_node, name, 2, &mask);
+	if (ret)
+		return dev_err_probe(&pdev->dev, ret, "Failed to get %s\n", name);
+
+	remap = regmap_test_bits(regmap, offset, mask);
+	if (remap && pdev->dev.dma_range_map) { /* dma-ranges is required */
+		ddata->axi_addr_offset = pdev->dev.bus_dma_limit + 1;
+		dev_dbg(&pdev->dev, "Address remapping enabled on AXI port, offset=%pap\n",
+			&ddata->axi_addr_offset);
+	}
+
+	return 0;
+}
+
 static u32 stm32_dma3_check_rif(struct stm32_dma3_ddata *ddata)
 {
 	u32 chan_reserved, mask = 0, i, ccidcfgr, invalid_cid = 0;
@@ -1942,6 +2076,13 @@ static int stm32_dma3_probe(struct platform_device *pdev)
 						 STM32_DMA3_MAX_BURST_LEN);
 	dev_dbg(&pdev->dev, "Burst is limited to %u beats\n", ddata->axi_max_burst_len);
 
+	/* If the controller has at least one AXI port, retrieve AXI port configuration */
+	if (port_is_axi(ddata->ports_max_dw[0]) || port_is_axi(ddata->ports_max_dw[1])) {
+		ret = stm32_dma3_get_axi_port_config(pdev, ddata);
+		if (ret)
+			goto err_clk_disable;
+	}
+
 	ret = stm32_dma3_lli_pool_create(pdev, ddata);
 	if (ret)
 		goto err_clk_disable;
-- 
2.39.5

